{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b301ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入依赖库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ccb46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      M Structure Adsorption species orientation       DFT      LGBM  \\\n",
      "0     V       @B4                *N2    (end-on) -1.000218 -1.015938   \n",
      "1     V       @B4                *N2   (side-on) -0.821077 -0.855509   \n",
      "2    Cu       @B4                *N2    (end-on) -0.497864 -0.465921   \n",
      "3    Cu       @B4                *N2   (side-on) -0.198403 -0.273015   \n",
      "4    Tc       @B4                *N2    (end-on) -1.341411 -1.238400   \n",
      "..   ..       ...                ...         ...       ...       ...   \n",
      "123  Tc       @B3                *N2    (end-on) -0.720426 -0.985053   \n",
      "124  Tc       @B3                *N2   (side-on) -0.345986 -0.499503   \n",
      "125  Ag       @B3                *N2   (side-on) -0.196123 -0.449861   \n",
      "126  Ir       @B3                *N2    (end-on) -0.700367 -0.696542   \n",
      "127  Ir       @B3                *N2   (side-on) -0.248328 -0.343387   \n",
      "\n",
      "    Type of data  NM   fB  NC     X     Z      R  Eligible  \n",
      "0       Training   1  1.0   4  1.63  23.0  252.0       1.0  \n",
      "1       Training   2  1.0   4  1.63  23.0  252.0       1.0  \n",
      "2       Training   1  1.0   4  1.90  29.0  217.0       0.0  \n",
      "3       Training   2  1.0   4  1.90  29.0  217.0       0.0  \n",
      "4       Training   1  1.0   4  2.10  43.0  252.0       1.0  \n",
      "..           ...  ..  ...  ..   ...   ...    ...       ...  \n",
      "123     Training   1  1.0   3  2.10  43.0  252.0       1.0  \n",
      "124     Training   2  1.0   3  2.10  43.0  252.0       0.0  \n",
      "125     Training   2  1.0   3  1.93  47.0  225.0       0.0  \n",
      "126     Training   1  1.0   3  2.20  77.0  240.0       1.0  \n",
      "127     Training   2  1.0   3  2.20  77.0  240.0       0.0  \n",
      "\n",
      "[128 rows x 14 columns]\n",
      "     NM   fB  NC     X     Z      R  Eligible\n",
      "0     1  1.0   4  1.63  23.0  252.0       1.0\n",
      "1     2  1.0   4  1.63  23.0  252.0       1.0\n",
      "2     1  1.0   4  1.90  29.0  217.0       0.0\n",
      "3     2  1.0   4  1.90  29.0  217.0       0.0\n",
      "4     1  1.0   4  2.10  43.0  252.0       1.0\n",
      "..   ..  ...  ..   ...   ...    ...       ...\n",
      "123   1  1.0   3  2.10  43.0  252.0       1.0\n",
      "124   2  1.0   3  2.10  43.0  252.0       0.0\n",
      "125   2  1.0   3  1.93  47.0  225.0       0.0\n",
      "126   1  1.0   3  2.20  77.0  240.0       1.0\n",
      "127   2  1.0   3  2.20  77.0  240.0       0.0\n",
      "\n",
      "[128 rows x 7 columns]\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "#参考文献doi:10.1039/c9ta12608b\n",
    "\n",
    "#读取数据表格\n",
    "df = pd.read_csv('./NRR数据集完整版.csv')\n",
    "print(df)\n",
    "#取出输入描述符X(倒数第7到倒数第2列)和标签Y(最后1列Eligible-作为NRR催化剂的可行性：1-可行，0-不可行，二分类)\n",
    "#各特征含义见文献\n",
    "#为简化演示，删去了库伦矩阵的PCA，并且仅以N2吸附能作为可行性判据\n",
    "data = df.iloc[:,-7:]\n",
    "print(data)\n",
    "#转化为numpy数组\n",
    "data = data.to_numpy()\n",
    "#特征数据标准化(可能提高模型性能，注释该部分代码以跳过)\n",
    "data[:,-7:-1] = StandardScaler().fit_transform(data[:,-7:-1])\n",
    "#shuffle数据集\n",
    "np.random.shuffle(data)\n",
    "\n",
    "#分配训练集和验证集\n",
    "#总样本数和训练样本数\n",
    "num_sample=data.shape[0]\n",
    "num_train=int(num_sample*0.8)\n",
    "print(num_train)\n",
    "#描述符和标签切片\n",
    "train_data=data[:num_train,:-1]\n",
    "train_lab=data[:num_train,-1]\n",
    "test_data=data[num_train:,:-1]\n",
    "test_lab=data[num_train:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1f3c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NN(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#构建文献中2个10维隐藏层的分类MLP\n",
    "#获取运行环境\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "#定义模型(复习)\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NN, self).__init__()\n",
    "        #利用Sequential容器快速定义一个2层10维的MLP模块\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.mlp(x)\n",
    "        #二分类可使用logistic回归\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = NN(input_dim=train_data.shape[1]).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d561a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义测试集上准确率(Accuracy)的计算方法\n",
    "def test(pred,lab):\n",
    "    t=pred.max(-1)[1]==lab\n",
    "    return torch.mean(t.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90efe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#其他超参\n",
    "criterion=nn.CrossEntropyLoss() # 使用CrossEntropyLoss损失\n",
    "optm=torch.optim.Adam(model.parameters(),lr=0.001) # 优化器\n",
    "epochs=500 # 训练500次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb32a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:50,Loss:0.6854,Accuracy：0.58\n",
      "Epoch:100,Loss:0.6529,Accuracy：0.69\n",
      "Epoch:150,Loss:0.6105,Accuracy：0.65\n",
      "Epoch:200,Loss:0.5668,Accuracy：0.69\n",
      "Epoch:250,Loss:0.5316,Accuracy：0.69\n",
      "Epoch:300,Loss:0.5075,Accuracy：0.73\n",
      "Epoch:350,Loss:0.4902,Accuracy：0.73\n",
      "Epoch:400,Loss:0.4766,Accuracy：0.73\n",
      "Epoch:450,Loss:0.4660,Accuracy：0.73\n",
      "Epoch:500,Loss:0.4578,Accuracy：0.73\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    # 指定模型为训练模式，计算梯度\n",
    "    model.train()\n",
    "    # 输入值都需要转化成torch的Tensor\n",
    "    x=torch.from_numpy(train_data).float()\n",
    "    y=torch.from_numpy(train_lab).long()\n",
    "    y_hat=model(x)\n",
    "    loss=criterion(y_hat,y) # 计算损失\n",
    "    optm.zero_grad() # 前一步的损失清零\n",
    "    loss.backward() # 反向传播\n",
    "    optm.step() # 优化\n",
    "    if (i+1)%50 ==0 : # 这里我们每10次输出相关的信息\n",
    "        # 指定模型为评估模式\n",
    "        model.eval()\n",
    "        test_in=torch.from_numpy(test_data).float()\n",
    "        test_l=torch.from_numpy(test_lab).long()\n",
    "        test_out=model(test_in)\n",
    "        # 使用我们的测试函数计算准确率\n",
    "        accu=test(test_out,test_l)\n",
    "        print(\"Epoch:{},Loss:{:.4f},Accuracy：{:.2f}\".format(i+1,loss.item(),accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "498ce545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     M Structure  Eligible\n",
      "0    V       @B4       1.0\n",
      "1    V       @B4       1.0\n",
      "2   Cu       @B4       0.0\n",
      "3   Cu       @B4       0.0\n",
      "4   Tc       @B4       1.0\n",
      "5   Tc       @B4       1.0\n",
      "6   Ru       @B4       1.0\n",
      "7   Ru       @B4       1.0\n",
      "8   Rh       @B4       0.0\n",
      "9   Rh       @B4       0.0\n",
      "10  Mo       @B4       1.0\n",
      "11  Mo       @B4       1.0\n",
      "12  Au       @B4       0.0\n",
      "13  Au       @B4       0.0\n",
      "14  Ag       @B4       0.0\n",
      "15  Ag       @B4       0.0\n",
      "16  Ir       @B4       1.0\n",
      "17  Ir       @B4       0.0\n",
      "18  Pt       @B4       0.0\n",
      "19  Pt       @B4       0.0\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#可以使用一下这个模型\n",
    "model.eval()\n",
    "#预测前20条数据\n",
    "test_df=df[:20]\n",
    "#输出中心金属单原子和配位结构，相应的标签，用于和预测结果对比\n",
    "print(test_df.iloc[:20,[0,1,-1]])\n",
    "#取出输入描述符X\n",
    "x = test_df.iloc[:,-7:-1]\n",
    "x = x.to_numpy()\n",
    "x = StandardScaler().fit_transform(x)\n",
    "x = torch.from_numpy(x).float()\n",
    "#预测\n",
    "y_hat = model(x)\n",
    "y_hat = y_hat.max(-1)[-1]\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86cfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f28104d83f364164a14023df7a8da16cfc0355892cfe84fa9cb246c3ca2d1159"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
